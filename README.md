# CNN SÄ±nÄ±flandÄ±rma
Harika bir karar. Projenin sadece koddan ibaret olmadÄ±ÄŸÄ±nÄ±, arkasÄ±nda ciddi bir **parametre mÃ¼hendisliÄŸi (Hyperparameter Engineering)** ve stratejik analiz olduÄŸunu gÃ¶steren, Github profilinde "Ben bu iÅŸi biliyorum" diye baÄŸÄ±racak profesyonel bir `README.md` hazÄ±rladÄ±m.

Az Ã¶nce senin yazdÄ±ÄŸÄ±n o harika teknik analiz kÄ±smÄ±nÄ± ("Dropout 0.5 vs 0.2" vb.) metnin **"Teknik Mimari ve Hiperparametre Analizi"** baÅŸlÄ±ÄŸÄ± altÄ±na Ã¶zel olarak yerleÅŸtirdim.

Bunu kopyala, GitHub'da `README.md` dosyanÄ±n iÃ§ine yapÄ±ÅŸtÄ±r.

-----

# ğŸ§µ CNN Ä°le Nesne SÄ±nÄ±flandÄ±rma: DÃ¼ÄŸme ve Makara Tespiti

## ğŸ“– Proje HakkÄ±nda

Bu proje, **Makine Ã–ÄŸrenmesi (BLG-407)** dersi kapsamÄ±nda geliÅŸtirilmiÅŸ bir GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme (Computer Vision) Ã§alÄ±ÅŸmasÄ±dÄ±r. Projenin temel amacÄ±, kÄ±sÄ±tlÄ± ve Ã¶zgÃ¼n bir veri seti Ã¼zerinde **Transfer Learning (Bilgi Transferi)** ile **SÄ±fÄ±rdan CNN EÄŸitimi (From Scratch)** yÃ¶ntemlerinin performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak ve "Small Data" (Az Veri) problemini aÅŸmak iÃ§in gerekli optimizasyon stratejilerini belirlemektir.

Proje kapsamÄ±nda **DÃ¼ÄŸmeler** ve **Makaralar** olmak Ã¼zere iki sÄ±nÄ±fÄ± iÃ§eren Ã¶zgÃ¼n bir veri seti oluÅŸturulmuÅŸ ve Ã¼Ã§ farklÄ± model mimarisi Ã¼zerinde kapsamlÄ± deneyler yapÄ±lmÄ±ÅŸtÄ±r.

-----

## ğŸ› ï¸ KullanÄ±lan Teknolojiler ve AraÃ§lar

  * **Dil:** Python 3.10
  * **Framework:** TensorFlow & Keras
  * **Veri Ä°ÅŸleme:** NumPy, Pandas
  * **GÃ¶rselleÅŸtirme:** Matplotlib
  * **Ortam:** Google Colab (GPU Destekli)

-----

## ğŸ“‚ Veri Seti (Dataset)

Veri seti, proje kapsamÄ±nda internetten alÄ±nmamÄ±ÅŸ, **tamamen Ã¶zgÃ¼n olarak** tarafÄ±mdan oluÅŸturulmuÅŸtur.

  * **SÄ±nÄ±flar:** `dugmeler` (Buttons) ve `makaralar` (Spools)
  * **Veri KaynaÄŸÄ±:** FarklÄ± aÃ§Ä±lardan ve Ä±ÅŸÄ±k koÅŸullarÄ±ndan Ã§ekilmiÅŸ fotoÄŸraflar.
  * **Toplam GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±:** 200 Adet.
  * **Ã–n Ä°ÅŸleme:**
      * Yeniden BoyutlandÄ±rma: `128x128` piksel.
      * Normalizasyon: Piksel deÄŸerleri 0-255 aralÄ±ÄŸÄ±ndan 0-1 aralÄ±ÄŸÄ±na Ã§ekilmiÅŸtir.
  * **Veri AyrÄ±mÄ±:** %80 EÄŸitim (Training) - %20 DoÄŸrulama (Validation).

-----

## ğŸ§  Uygulanan Modeller ve Stratejiler

BaÅŸarÄ±yÄ± artÄ±rmak ve yÃ¶ntemleri kÄ±yaslamak adÄ±na 3 aÅŸamalÄ± bir yol izlenmiÅŸtir:

### 1ï¸âƒ£ Model 1: Transfer Learning (VGG16)

  * **YÃ¶ntem:** ImageNet Ã¼zerinde eÄŸitilmiÅŸ **VGG16** modelinin aÄŸÄ±rlÄ±klarÄ± kullanÄ±larak "Fine-Tuning" yapÄ±lmÄ±ÅŸtÄ±r.
  * **SonuÃ§:** HazÄ±r modelin gÃ¼Ã§lÃ¼ Ã¶zellik Ã§Ä±karÄ±cÄ±larÄ± sayesinde %97.50 baÅŸarÄ±ya ulaÅŸÄ±lmÄ±ÅŸtÄ±r.

### 2ï¸âƒ£ Model 2: Basit CNN (SÄ±fÄ±rdan EÄŸitim)

  * **YÃ¶ntem:** 3 Bloklu (Conv2D + MaxPool) Ã¶zel bir CNN mimarisi kurulmuÅŸtur.
  * **GÃ¶zlem:** Veri artÄ±rma ve optimizasyon yapÄ±lmadÄ±ÄŸÄ± iÃ§in modelin veriyi **ezberlediÄŸi (Overfitting)** ve Loss deÄŸerinin 1.06 seviyelerine Ã§Ä±ktÄ±ÄŸÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.

### 3ï¸âƒ£ Model 3: GeliÅŸmiÅŸ CNN (Optimizasyon & Augmentation)

  * **YÃ¶ntem:** Model 2'nin optimize edilmiÅŸ halidir.
  * **Uygulanan Stratejiler:**
      * **Data Augmentation:** Veri seti sanal olarak (dÃ¶ndÃ¼rme, kaydÄ±rma, zoom) artÄ±rÄ±ldÄ±.
      * **ModelCheckpoint:** EÄŸitim sÄ±rasÄ±nda en iyi performans gÃ¶steren aÄŸÄ±rlÄ±klar kaydedildi.
      * **Hiperparametre AyarÄ±:** Dropout ve Learning Rate optimize edildi (AÅŸaÄŸÄ±da detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r).

-----

## ğŸ§ª Teknik Mimari ve Hiperparametre Analizi

Bu Ã§alÄ±ÅŸmada yapÄ±lan hiperparametre deÄŸiÅŸikliklerinin model baÅŸarÄ±sÄ±na etkisi detaylÄ±ca analiz edilmiÅŸtir:

### 1\. Filtre SayÄ±sÄ± ve Mimari

Model 2 ve Model 3'te **32-64-128** filtre yapÄ±sÄ± korunmuÅŸtur. Bu yapÄ±, 128x128 boyutundaki basit morfolojiye sahip nesneler (DÃ¼ÄŸme/Makara) iÃ§in yeterli Ã¶zellik Ã§Ä±karÄ±mÄ± (feature extraction) saÄŸlamaktadÄ±r. Daha derin bir aÄŸ (Ã¶rneÄŸin 256 filtre) bu veri boyutunda gereksiz parametre artÄ±ÅŸÄ±na ve iÅŸlem yÃ¼kÃ¼ne yol aÃ§acaÄŸÄ± iÃ§in tercih edilmemiÅŸtir.

### 2\. Dropout OranÄ±nÄ±n Kritik Etkisi (0.5 vs 0.2)

  * **Model 2 Durumu:** Standart **0.5** Dropout kullanÄ±lmÄ±ÅŸ ancak model az veriyle yeterince Ã¶ÄŸrenemeden nÃ¶ronlar kapatÄ±ldÄ±ÄŸÄ± iÃ§in performans dÃ¼ÅŸÃ¼k kalmÄ±ÅŸtÄ±r (Underfitting sinyalleri).
  * **Model 3 Ã‡Ã¶zÃ¼mÃ¼:** Dropout oranÄ± **0.2'ye** dÃ¼ÅŸÃ¼rÃ¼lerek modelin kapasitesi artÄ±rÄ±lmÄ±ÅŸ, ancak **Veri ArtÄ±rma (Augmentation)** ile ezberleme (overfitting) dengelenmiÅŸtir.

### 3\. Ã–ÄŸrenme OranÄ± (Learning Rate) Optimizasyonu

  * **Model 2 Durumu:** VarsayÄ±lan Learning Rate (0.001) kullanÄ±ldÄ±ÄŸÄ±nda Loss grafiÄŸinde kararsÄ±z dalgalanmalar gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.
  * **Model 3 Ã‡Ã¶zÃ¼mÃ¼:** Oran **0.0001'e** Ã§ekilerek modelin gradyan iniÅŸinde (gradient descent) daha kÃ¼Ã§Ã¼k ve emin adÄ±mlarla ilerlemesi saÄŸlanmÄ±ÅŸ, bu da baÅŸarÄ± artÄ±ÅŸÄ±na doÄŸrudan katkÄ±da bulunmuÅŸtur.

-----

## ğŸ“Š Deneysel SonuÃ§larÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±

AÅŸaÄŸÄ±daki tablo, Ã¼Ã§ farklÄ± modelin baÅŸarÄ± oranlarÄ±nÄ± ve hata paylarÄ±nÄ± (Loss) Ã¶zetlemektedir.

| Model No | Mimari Tipi | Veri ArtÄ±rma | Dropout & LR | Test BaÅŸarÄ±sÄ± (Accuracy) | Test KaybÄ± (Loss) | SonuÃ§ Yorumu |
| :--- | :--- | :---: | :--- | :---: | :---: | :--- |
| **Model 1** | Transfer Learning (VGG16) | HayÄ±r | 0.5 / 0.0001 | **%97.50** | **0.1304** | HazÄ±r aÄŸÄ±rlÄ±klar sayesinde kusursuz ayrÄ±m saÄŸlandÄ±. |
| **Model 2** | Basit CNN (SÄ±fÄ±rdan) | HayÄ±r | 0.5 / Default | **%70.00** | **1.0651** | Veri azlÄ±ÄŸÄ± sebebiyle aÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) yaÅŸandÄ±. Loss Ã§ok yÃ¼ksek. |
| **Model 3** | **GeliÅŸmiÅŸ CNN** | **EVET** | **0.2 / 0.0001** | **%82.50** | **0.6322** | Veri artÄ±rma ve LR optimizasyonu ile **Loss yarÄ± yarÄ±ya dÃ¼ÅŸÃ¼rÃ¼ldÃ¼**. KararlÄ± Ã¶ÄŸrenme saÄŸlandÄ±. |

### ğŸ“ˆ SonuÃ§ DeÄŸerlendirmesi

Model 1 (Transfer Learning) en yÃ¼ksek baÅŸarÄ±yÄ± verse de, donanÄ±m maliyeti yÃ¼ksektir. **Model 3**, uygulanan mÃ¼hendislik teknikleri sayesinde, sÄ±fÄ±rdan eÄŸitilen ve az veriye sahip bir modelin bile **%80 barajÄ±nÄ± aÅŸabileceÄŸini** kanÄ±tlamÄ±ÅŸtÄ±r. Ã–zellikle Model 2'ye kÄ±yasla Loss deÄŸerindeki ciddi dÃ¼ÅŸÃ¼ÅŸ, modelin gÃ¼venilirliÄŸini artÄ±rmÄ±ÅŸtÄ±r.

-----

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Projeyi kendi bilgisayarÄ±nÄ±zda veya Google Colab Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

1.  Repoyu klonlayÄ±n:
    ```bash
    git clone https://github.com/kullanici_adiniz/Proje_Ismi.git
    ```
2.  Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
    ```bash
    pip install tensorflow numpy matplotlib pandas
    ```
3.  Notebook dosyalarÄ±nÄ± (`Model1.ipynb`, `Model2.ipynb`, `Model3.ipynb`) sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n.

-----



Ceyda Metin
**BÃ¶lÃ¼m:** Bilgisayar MÃ¼hendisliÄŸi
